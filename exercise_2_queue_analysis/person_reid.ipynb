{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720334a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def FrameCapture(path): \n",
    "    image_list = []\n",
    "    # Path to video file \n",
    "    vidObj = cv2.VideoCapture(path) \n",
    "  \n",
    "    # Get the frame rate of the video\n",
    "    fps = int(vidObj.get(cv2.CAP_PROP_FPS))\n",
    "  \n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "  \n",
    "    # checks whether frames were extracted \n",
    "    success = True\n",
    "  \n",
    "    # Calculate how many frames between each save\n",
    "    save_interval = fps // 10\n",
    "  \n",
    "    while success: \n",
    "        # vidObj object calls read function to extract frames \n",
    "        success, image = vidObj.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Save 3 frames per second\n",
    "        if count % save_interval == 0:\n",
    "            image_list.append(image)\n",
    "        count += 1\n",
    "\n",
    "    return image_list\n",
    "\n",
    "list_of_images = FrameCapture('first-video.mp4')\n",
    "print(f\"Extracted {len(list_of_images)} frames from the video.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12faa2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frame = list_of_images[0]\n",
    "print(sample_frame.shape)\n",
    "sample_frame = cv2.cvtColor(sample_frame, cv2.COLOR_BGR2RGB)\n",
    "sample_frame = cv2.line(sample_frame, (965,1000), (965,0), (0, 255, 0),3)\n",
    "sample_frame = cv2.line(sample_frame, (980,1000), (980,0), (0, 255, 0),3)\n",
    "\n",
    "sample_frame = cv2.line(sample_frame, (1910,1000), (1910,0), (0, 255, 0),3)\n",
    "\n",
    "\n",
    "sample_frame = cv2.line(sample_frame, (0,650), (1910,650), (0, 255, 0),3)\n",
    "\n",
    "plt.imshow(sample_frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55870472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The one\n",
    "import faiss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import uuid\n",
    "import torchreid\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 50\n",
    "color = (0, 0, 255)\n",
    "thickness = 5\n",
    "\n",
    "# Load models\n",
    "\n",
    "yolo_model = YOLO('yolov3u.pt')##\n",
    "\n",
    "extractor = torchreid.utils.FeatureExtractor(\n",
    "    model_name='resnet50',\n",
    "    model_path='resnet50_msmt17_combineall_256x128_amsgrad_ep150_stp60_lr0.0015_b64_fb10_softmax_labelsmooth_flip_jitter.pth',\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# ReID gallery with embedding history\n",
    "embedding_history = defaultdict(lambda: deque(maxlen=1000))\n",
    "embedding_dict = {}\n",
    "people_in_queue = {}\n",
    "timing_dict = {}\n",
    "queue_order_dict ={}\n",
    "time_diff = []\n",
    "gallery_ids = []\n",
    "\n",
    "similarity_threshold = 0.66 #0.65\n",
    "\n",
    "def assign_id_for_person(person_features,conf):\n",
    "    person_features = F.normalize(torch.tensor(person_features), p=2, dim=1).cpu().numpy()[0]  # shape: (512,)\n",
    "\n",
    "    best_id = None\n",
    "    best_score = -1\n",
    "\n",
    "    for pid, history in embedding_history.items():\n",
    "        for prev_feat in history:\n",
    "            score = F.cosine_similarity(torch.tensor(person_features), torch.tensor(prev_feat), dim=0).item()\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_id = pid\n",
    "        \n",
    "    print('best_score', best_score)\n",
    "    if best_score > similarity_threshold:\n",
    "        embedding_history[best_id].append(person_features)\n",
    "        return best_id\n",
    "    else:\n",
    "        if conf > 0.81:\n",
    "            new_id = str(uuid.uuid4())\n",
    "            embedding_dict[new_id] = person_features\n",
    "            people_in_queue[new_id] = person_features\n",
    "            embedding_history[new_id].append(person_features)\n",
    "            gallery_ids.append(new_id)\n",
    "            timing_dict[new_id] = time.time()\n",
    "            return new_id\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "frame_count = 1\n",
    "avg_time = None\n",
    "for image in list_of_images[:]:\n",
    "    frame = image.copy()\n",
    "    results = yolo_model.predict(source=frame, conf=0.75, classes=[0])#0.75\n",
    "\n",
    "    for result in results:\n",
    "        queue_order_dict = {}\n",
    "        people_location = []\n",
    "        for det, conf in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.conf.cpu().numpy()):\n",
    "            x1, y1, x2, y2 = map(int, det)\n",
    "            if x1 in range(950, 980):\n",
    "                continue\n",
    "            \n",
    "\n",
    "            width = abs(x2 - x1)\n",
    "            height = abs(y2 - y1)\n",
    "            area = width * height\n",
    "\n",
    "            w = x2 - x1\n",
    "            h = y2 - y1\n",
    "            aspect_ratio = h / (w + 1e-5)\n",
    "            \n",
    "            if area < 16300:\n",
    "                continue\n",
    "            '''\n",
    "            if conf < 0.7 and area <18100:\n",
    "                continue\n",
    "            if height < 180:\n",
    "                continue\n",
    "            '''\n",
    "\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            #margin_y = int(0.1 * (y2 - y1))\n",
    "            #crop = frame[y1 + margin_y:y2 - margin_y, x1:x2]\n",
    "            #crop = cv2.resize(crop, (128, 256))\n",
    "\n",
    "            embedding = extractor(crop)\n",
    "            person_id = assign_id_for_person(embedding,conf)\n",
    "            print('person_id', person_id)\n",
    "            if y1 < 650:\n",
    "                if queue_order_dict.get(person_id) is None:\n",
    "                    queue_order_dict[person_id] = x1\n",
    "                else:\n",
    "                    queue_order_dict[person_id] = max(queue_order_dict[person_id], x1)\n",
    "\n",
    "            print('queue_order_dict', queue_order_dict)\n",
    "\n",
    "\n",
    "            if x2 > 1910:\n",
    "                time_diff.append(time.time() - timing_dict[person_id])\n",
    "                if person_id is not None:\n",
    "                    if person_id in people_in_queue:\n",
    "                        del people_in_queue[person_id]\n",
    "                        \n",
    "\n",
    "            # Draw\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            '''\n",
    "            if len(time_diff) > 0:\n",
    "                avg_time = sum(time_diff) / len(time_diff)\n",
    "                avg_time = avg_time/20\n",
    "                avg_time = round(avg_time)\n",
    "            else:\n",
    "                avg_time = None\n",
    "            '''\n",
    "            if x2 > 1910 and avg_time is None:\n",
    "                avg_time = (time.time() - timing_dict[person_id])/20\n",
    "            \n",
    "\n",
    "            avg_x = (x1 + x2) / 2\n",
    "            people_location.append([x1, y1,person_id,avg_x])\n",
    "\n",
    "        \n",
    "            #if person_id is not None:\n",
    "            #    cv2.putText(frame, f\"ID: {person_id[:5]} | Order: {queue_order_dict[person_id]}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "            #cv2.putText(frame, f' People count: {len(embedding_dict)} | Avg. time: {avg_time} sec', (0, 100), font, 2, (255, 255, 255), 5)\n",
    "            cv2.putText(frame, f' People count: {len(people_in_queue)}', (0, 100), font, 2, (255, 255, 255), 5)\n",
    "\n",
    "            print('conf', conf)\n",
    "            print('area', area)\n",
    "            print('aspect_ratio', aspect_ratio, 'width', width, 'height', height)\n",
    "        order = 1\n",
    "        people_location.sort(key=lambda x: x[3], reverse=True)\n",
    "        print('people_location', people_location)\n",
    "        taken_into_account = {}\n",
    "        for list in people_location:\n",
    "            x1, y1, person_id,avg_x = list\n",
    "            if person_id is not None:\n",
    "                if taken_into_account.get(person_id) is None:\n",
    "                    cv2.putText(frame, f\"ID: {person_id[:5]}\", (x1, y1 - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, f\"#: {order}\", (x1, y1 - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                    if avg_time is not None:\n",
    "                        eta = (order - 1) * avg_time #- frame_count * 0.05 \n",
    "                        if eta < 0:\n",
    "                            eta = 0\n",
    "                        eta = round(eta)\n",
    "                        cv2.putText(frame, f\"ETA:: {eta} sec\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "                    taken_into_account[person_id] = order\n",
    "                    print('taken_into_account', taken_into_account)\n",
    "                    order += 1\n",
    "                else:\n",
    "                    cv2.putText(frame, f\"ID: {person_id[:5]}\", (x1, y1 - 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, f\"#: {taken_into_account[person_id]}\", (x1, y1 - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                    if avg_time is not None:\n",
    "                        eta = (taken_into_account[person_id] - 1) * avg_time #- frame_count * 0.02\n",
    "                        if eta < 0:\n",
    "                            eta = 0\n",
    "                        eta = round(eta)\n",
    "                        cv2.putText(frame, f\"ETA:: {eta} sec\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    cv2.imwrite(f'count5/frame_{frame_count}.jpg', frame)\n",
    "    frame_count += 1\n",
    "    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    #plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6781776c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def generate_video():\n",
    "    image_folder = 'count5'\n",
    "    video_name = 'first-video-counted_3.mp4'\n",
    "\n",
    "    images = [img for img in os.listdir(image_folder) if img.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "    images.sort(key=lambda x: int(x.split('_')[1].split('.')[0]))  # Sort by frame number\n",
    "\n",
    "    print(\"Images:\", images)\n",
    "\n",
    "    # Set frame from the first image\n",
    "    frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "\n",
    "    # Video writer to create .avi file\n",
    "    frame_rate = 10  # frame per second\n",
    "    video = cv2.VideoWriter(video_name, cv2.VideoWriter_fourcc(*'DIVX'), frame_rate, (width, height))\n",
    "\n",
    "    # Appending images to video\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "    # Release the video file\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Video generated successfully!\")\n",
    "\n",
    "# Calling the function to generate the video\n",
    "generate_video()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
